<!DOCTYPE html>



<html lang="en" itemscope="" itemtype="http://schema.org/QAPage">

<!-- Mirrored from c.programmingpedia.net/en/knowledge-base/8187745/audio-output-with-video-processing-with-opencv by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 16 Jan 2021 10:13:58 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <!-- webmaster tools -->
        <meta name="google-site-verification" content="" />
        <!-- Open Graph Tags -->
        <meta name="title" property="og:title" content="[SOLVED] Audio output with video processing with opencv | C Language Knowledge Base">
        <meta name="description" property="og:description" content="[SOLVED] Audio output with video processing with opencv | C Language Knowledge Base">
        <title>[SOLVED] Audio output with video processing with opencv | C Language Knowledge Base</title>

    

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">
    
        <style>
            body{margin:0;}img{max-width:100%;}ul{margin-top:0;margin-bottom:1rem;}.list-inline{padding-left:0;list-style:none;}.list-inline-item{display:inline-block;}.list-inline-item:not(:last-child){margin-right:.5rem;}.site-header{display:flex;height:60px;}.site-main,.site-footer{display:flex;}.col-aside-left-and-sidebar .col-aside-left,.col-sidebar,.col-content,.col-aside-right{position:relative;}.site-header .col-aside-left-and-sidebar-inner,.site-header .col-aside-right-inner,.site-header .col-content-inner{height:60px;}.site-header .col-aside-left-and-sidebar-inner,.site-header .col-aside-right-inner{position:fixed;z-index:1;}.site-main .col-aside-left-inner,.site-main .col-sidebar-inner,.site-main .col-aside-right-inner{height:calc(100vh - 60px);position:fixed;}.site-main .col-sidebar-overflow{height:calc(100vh - 60px);position:relative;overflow-x:hidden;overflow-y:auto;}.col-aside-left-and-sidebar,.col-aside-left-and-sidebar-inner{width:calc(50% - 450px);}.col-aside-left,.col-aside-left-inner{width:calc(50% - 750px);}.col-sidebar,.col-sidebar-inner{width:300px;}.col-content,.col-content-inner{width:1200px;}.col-aside-right,.col-aside-right-inner{width:calc(50% - 750px);}@media(max-width:1869px){.col-aside-left-and-sidebar,.col-aside-left-and-sidebar-inner{width:calc(50% - 500px);}.col-aside-left,.col-aside-left-inner{display:none;}.col-sidebar,.col-sidebar-inner{width:calc(50% - 500px);}.col-content,.col-content-inner{width:1000px;}.col-aside-right,.col-aside-right-inner{width:calc(50% - 500px);}}@media(max-width:1549px){.col-aside-left-and-sidebar,.col-aside-left-and-sidebar-inner{width:calc(50% - 400px);}.col-sidebar,.col-sidebar-inner{width:calc(50% - 400px);}.col-content,.col-content-inner{width:800px;}.col-aside-right,.col-aside-right-inner{width:calc(50% - 400px);}}@media(max-width:1229px){.col-aside-left-and-sidebar,.col-aside-left-and-sidebar-inner{width:300px;}.col-sidebar,.col-sidebar-inner{width:300px;}.col-content{width:calc(100% - 300px);}.col-content-inner{width:100%;}.col-aside-right,.col-aside-right-inner{display:none;}}@media(max-width:1000px){.col-aside-left-and-sidebar,.col-aside-left-and-sidebar-inner{width:250px;}.col-sidebar,.col-sidebar-inner{width:250px;}.col-content{width:calc(100% - 250px);}}@media(max-width:767px){.col-aside-left-and-sidebar,.col-aside-left-and-sidebar-inner{display:none;}.col-sidebar,.col-sidebar-inner{display:none;}.col-content{width:100%;}.site-main{display:initial;}.site-main .col-sidebar,.site-main .col-sidebar-inner{display:initial;width:100%;position:relative;}.site-main .col-sidebar-overflow{height:calc(30vh);}}.site-header .col-aside-left-and-sidebar-inner,.site-header .col-aside-right-inner,.site-header .col-content-inner{box-shadow:rgba(116,129,141,.1) 0 3px 8px 0;border-bottom:1px solid #d4dadf;}.site-header .col-aside-left-and-sidebar-inner,.site-header .col-aside-right-inner,.site-main .col-aside-left-inner,.site-main .col-sidebar-inner,.site-main .col-aside-right-inner{background:#f5f7f9 none repeat scroll 0% 0%;}.site-header .col-aside-left-and-sidebar-inner,.site-main .col-sidebar-inner{border-right:1px solid #e6ecf1;}.site-header .col-aside-right,.site-main .col-aside-right{border-left:1px solid #e6ecf1;}.brand{font-size:24px;font-weight:bold;height:100%;text-align:right;margin-right:20px;margin-top:10px;}
        </style>
    <link rel="stylesheet" type="text/css" href="../../../styles/master.min0e4d.css?v=todo">
    <!-- to fix/move? -->
    

    
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-55584370-32"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-131737769-1');
    </script>


</head>
<body>


<div class="site-header">
    <div class="col-aside-left-and-sidebar">
        <div class="col-aside-left-and-sidebar-inner">
            <div class="brand">
                <i class="fas fa-yin-yang" style="color: #0056b3;"></i>&nbsp;
                C Language Pedia
            </div>
        </div>
    </div>
    <div class="col-content">
        <div class="col-content-inner">
<div>
    <ul class="list-inline">
        <li class="list-inline-item"><a href="../../../index.html">Tutorial</a></li>
            <li class="list-inline-item"><a href="../../knowledge-base.html">Knowledge-Base</a></li>

            <li class="list-inline-item"><a href="../../awesome-learning/book.html">Awesome</a></li>
    </ul>
</div>

<style>
    .site-header .col-content .list-inline {
        padding-left: 20px;
        padding-top: 15px;

        font-weight: bold;
    }
</style>
        </div>
    </div>
    <div class="col-aside-right">
        <div class="col-aside-right-inner">
            
        </div>
    </div>
</div>
<div class="site-main">
    <div class="col-aside-left">
        <div class="col-aside-left-inner">
            
        </div>
    </div>
    <div class="col-sidebar">
        <div class="col-sidebar-inner">

            <div class="col-sidebar-overflow">
                
            </div>

        </div>
    </div>
    <div class="col-content">
        <div class="col-content-inner">
            


<div id="knowledge-base" class="kb-details">
    <div class="row">
        <div class="col-lg-1 col-xl-1">
        </div>
        <div class="col-lg-9 col-xl-9" itemprop="mainEntity" itemscope itemtype="http://schema.org/Question">
            <div class="container-h1">
                <h1 itemprop="name" id="audio-output-with-video-processing-with-opencv">Audio output with video processing with opencv</h1>
                <div class="tag-list">
                        <span class="tag-item"><a href="../tag/audio.html">audio</a></span>
                        <span class="tag-item"><a href="../tag/c.html">c</a></span>
                        <span class="tag-item"><a href="../tag/cplusplus.html">c++</a></span>
                        <span class="tag-item"><a href="../tag/ffmpeg.html">ffmpeg</a></span>
                        <span class="tag-item"><a href="../tag/opencv.html">opencv</a></span>
                </div>
            </div>
            <br>
            <div class="search-results-container">
                <div class="row">
                    <div class="col-sm-6">
                        <div class="block-question">
                            <div class="container-question">
                                <i class="fab fa-stack-overflow" style="font-size: 32px; position: absolute; left: -15px; top: -15px;"></i>
                                <h3 id="question">Question</h3>
                                <div itemprop="text">
                                    <p>I am processing video with opencv, but at the same time I need to play audio and simply control it, like loud or current frame number.</p>

<p>I think I should create a parallel process with ffmpeg, but I don't know how to do so.  Can you explain what to do?</p>

<p>Or do you know another solution?</p>

                                </div>

                                <div class="d-flex justify-content-between align-items-center">
                                    <div class="profile-container">
                                        <div class="profile-details-container d-flex align-items-center">
                                            <div class="asker-name" itemprop="author" itemscope itemtype="https://schema.org/Person"><a href="https://stackoverflow.com/users/891699/victor1234" target="_blank"><span itemprop="name">victor1234</span></a></div>
                                        </div>
                                    </div>
                                </div>
                                
                                <div style="display: none">
                                    <div itemprop="answerCount">1</div>
                                    <div itemprop="upvoteCount">15</div>
                                    <div itemprop="dateCreated">11/19/2011 7:59:50 AM</div>
                                </div>
                            </div>
                        </div>
                        
                        <br/>
                    </div>
                    <div class="col-sm-6">
                            <div id="answer-0" class="block-question answer" itemprop="acceptedAnswer" itemscope itemtype="http://schema.org/Answer">
                                <div class="container-question">
                                    <h3 id="accepted-answer">Accepted Answer</h3>
                                    <div itemprop="text">
                                        <p>I think <strong>ffmpeg</strong> should be used <strong>to play audio and SDL for video</strong> in this case.</p>

<p>After opening the file with OpenCV and processing the frame, you can use <code>OpenCV -&gt; SDL</code> to display it while retrieving the audio frames through ffmpeg and playing them with SDL.</p>

<p><strong><a href="http://dranger.com/ffmpeg/tutorial01.html" rel="noreferrer">Here is a nice collection of ffmpeg/SDL tutorials!</a></strong></p>

<p>I also found a nice post that shows how to capture frames from a video file using ffmpeg, store them in OpenCV <code>cv::Mat</code> and display the result in a OpenCV window. But this way you can't play audio since OpenCV doesn't deal with that.</p>

<p>You might be interested in reading <a href="https://stackoverflow.com/q/8106846/176769">this post</a> as well: <a href="https://stackoverflow.com/q/8106846/176769">How to avoid a growing delay with ffmpeg between sound and raw video data ?</a></p>

<p><strong>EDIT:</strong></p>

<p>I spent the last 4hrs coding a prototype to demonstrate how it's done. <strong>This demo reads video frames through OpenCV</strong> (so you can process them) <strong>and audio through ffmpeg</strong>, and SDL is used to play both! There are 2 limitations in this demo you must be aware: <strong>1</strong> - it assumes you are working with an OpenCV image packed as BGR (24bits), and <strong>2</strong> - audio and video are not being sync! Yes, I left have some work for you to do  (yeeeey). But don't panic, <a href="http://dranger.com/ffmpeg/tutorial06.html" rel="noreferrer">page 6</a> has some ideas!</p>

<p>It's important to <a href="http://dranger.com/ffmpeg/tutorial06.html" rel="noreferrer">sync audio and video</a> because you will be doing some processing on the frames, and that will certainly make the video and audio go out of sync real fast since they are being played independently of each other.</p>

<p>The <strong>ffmpeg tutorials</strong> I suggested above are very <strong>very important</strong> to understand the code, <a href="http://dranger.com/ffmpeg/tutorial03.html" rel="noreferrer">a lot of code from this demo came from there</a>. They show how to deal with SDL, and how to read packets of audio/video streams.</p>

<pre><code>#include &lt;highgui.h&gt;
#include &lt;cv.h&gt;

extern "C"
{
#include &lt;SDL.h&gt;
#include &lt;SDL_thread.h&gt;
#include &lt;avcodec.h&gt;
#include &lt;avformat.h&gt;
}

#include &lt;iostream&gt;
#include &lt;stdio.h&gt;
//#include &lt;malloc.h&gt;

using namespace cv;    

#define SDL_AUDIO_BUFFER_SIZE 1024

typedef struct PacketQueue 
{
  AVPacketList *first_pkt, *last_pkt;
  int nb_packets;
  int size;
  SDL_mutex *mutex;
  SDL_cond *cond;
} PacketQueue;
PacketQueue audioq;

int audioStream = -1;
int videoStream = -1;
int quit = 0;

SDL_Surface* screen = NULL; 
SDL_Surface* surface = NULL;

AVFormatContext* pFormatCtx = NULL;
AVCodecContext* aCodecCtx = NULL;
AVCodecContext* pCodecCtx = NULL;  

void show_frame(IplImage* img)
{
    if (!screen) 
    {
        screen = SDL_SetVideoMode(img-&gt;width, img-&gt;height, 0, 0);
        if (!screen) 
        {
            fprintf(stderr, "SDL: could not set video mode - exiting\n");
            exit(1);
        }
    }

    // Assuming IplImage packed as BGR 24bits
    SDL_Surface* surface = SDL_CreateRGBSurfaceFrom((void*)img-&gt;imageData,
                img-&gt;width,
                img-&gt;height,
                img-&gt;depth * img-&gt;nChannels,
                img-&gt;widthStep,
                0xff0000, 0x00ff00, 0x0000ff, 0
                );

    SDL_BlitSurface(surface, 0, screen, 0);

    SDL_Flip(screen);
}

void packet_queue_init(PacketQueue *q) 
{
    memset(q, 0, sizeof(PacketQueue));
    q-&gt;mutex = SDL_CreateMutex();
    q-&gt;cond = SDL_CreateCond();
}

int packet_queue_put(PacketQueue *q, AVPacket *pkt) 
{
    AVPacketList *pkt1;
    if (av_dup_packet(pkt) &lt; 0) 
    {
        return -1;
    }

    //pkt1 = (AVPacketList*) av_malloc(sizeof(AVPacketList));
    pkt1 = (AVPacketList*) malloc(sizeof(AVPacketList));
    if (!pkt1) return -1;
    pkt1-&gt;pkt = *pkt;
    pkt1-&gt;next = NULL;

    SDL_LockMutex(q-&gt;mutex);

    if (!q-&gt;last_pkt)
        q-&gt;first_pkt = pkt1;
    else
        q-&gt;last_pkt-&gt;next = pkt1;

    q-&gt;last_pkt = pkt1;
    q-&gt;nb_packets++;
    q-&gt;size += pkt1-&gt;pkt.size;
    SDL_CondSignal(q-&gt;cond);

    SDL_UnlockMutex(q-&gt;mutex);
    return 0;
}

static int packet_queue_get(PacketQueue *q, AVPacket *pkt, int block)
{
    AVPacketList *pkt1;
    int ret;

    SDL_LockMutex(q-&gt;mutex);

    for (;;) 
    {      
        if( quit) 
        {
            ret = -1;
            break;
        }

        pkt1 = q-&gt;first_pkt;
        if (pkt1) 
        {
            q-&gt;first_pkt = pkt1-&gt;next;
            if (!q-&gt;first_pkt)
                q-&gt;last_pkt = NULL;

                q-&gt;nb_packets--;
            q-&gt;size -= pkt1-&gt;pkt.size;
            *pkt = pkt1-&gt;pkt;
            //av_free(pkt1);
            free(pkt1);
            ret = 1;
            break;
        } 
        else if (!block) 
        {
            ret = 0;
            break;
        } 
        else 
        {
            SDL_CondWait(q-&gt;cond, q-&gt;mutex);
        }
    }

    SDL_UnlockMutex(q-&gt;mutex);
    return ret;
}

int audio_decode_frame(AVCodecContext *aCodecCtx, uint8_t *audio_buf, int buf_size) 
{
    static AVPacket pkt;
    static uint8_t *audio_pkt_data = NULL;
    static int audio_pkt_size = 0;

    int len1, data_size;

    for (;;) 
    {
        while (audio_pkt_size &gt; 0) 
        {
            data_size = buf_size;
            len1 = avcodec_decode_audio2(aCodecCtx, (int16_t*)audio_buf, &amp;data_size, 
                                         audio_pkt_data, audio_pkt_size);
            if (len1 &lt; 0) 
            {
                /* if error, skip frame */
                audio_pkt_size = 0;
                break;
            }
            audio_pkt_data += len1;
            audio_pkt_size -= len1;
            if (data_size &lt;= 0) 
            {
                /* No data yet, get more frames */
                continue;
            }
            /* We have data, return it and come back for more later */
            return data_size;
        }

            if (pkt.data)
            av_free_packet(&amp;pkt);

        if (quit) return -1;

        if (packet_queue_get(&amp;audioq, &amp;pkt, 1) &lt; 0) return -1;

        audio_pkt_data = pkt.data;
        audio_pkt_size = pkt.size;
    }
}

void audio_callback(void *userdata, Uint8 *stream, int len) 
{
    AVCodecContext *aCodecCtx = (AVCodecContext *)userdata;
    int len1, audio_size;

    static uint8_t audio_buf[(AVCODEC_MAX_AUDIO_FRAME_SIZE * 3) / 2];
    static unsigned int audio_buf_size = 0;
    static unsigned int audio_buf_index = 0;

    while (len &gt; 0) 
    {
        if (audio_buf_index &gt;= audio_buf_size) 
        {
            /* We have already sent all our data; get more */
            audio_size = audio_decode_frame(aCodecCtx, audio_buf, sizeof(audio_buf));
            if(audio_size &lt; 0) 
            {
                /* If error, output silence */
                audio_buf_size = 1024; // arbitrary?
                memset(audio_buf, 0, audio_buf_size);
            } 
            else 
            {
                audio_buf_size = audio_size;
            }
            audio_buf_index = 0;
        }

        len1 = audio_buf_size - audio_buf_index;
        if (len1 &gt; len)
            len1 = len;

            memcpy(stream, (uint8_t *)audio_buf + audio_buf_index, len1);
        len -= len1;
        stream += len1;
        audio_buf_index += len1;
    }
}

void setup_ffmpeg(char* filename)
{
    if (av_open_input_file(&amp;pFormatCtx, filename, NULL, 0, NULL) != 0)
    {
        fprintf(stderr, "FFmpeg failed to open file %s!\n", filename);
        exit(-1); 
    }

    if (av_find_stream_info(pFormatCtx) &lt; 0)
    {
        fprintf(stderr, "FFmpeg failed to retrieve stream info!\n");
        exit(-1); 
    }

    // Dump information about file onto standard error
    dump_format(pFormatCtx, 0, filename, 0);

    // Find the first video stream
    int i = 0;
    for (i; i &lt; pFormatCtx-&gt;nb_streams; i++)
    {
        if (pFormatCtx-&gt;streams[i]-&gt;codec-&gt;codec_type == CODEC_TYPE_VIDEO &amp;&amp; videoStream &lt; 0) 
        {
            videoStream = i;
        }

        if (pFormatCtx-&gt;streams[i]-&gt;codec-&gt;codec_type == CODEC_TYPE_AUDIO &amp;&amp; audioStream &lt; 0) 
        {
            audioStream = i;
        }
    }

    if (videoStream == -1)
    {
        fprintf(stderr, "No video stream found in %s!\n", filename);
        exit(-1); 
    }  

    if (audioStream == -1)
    {
        fprintf(stderr, "No audio stream found in %s!\n", filename);
        exit(-1); 
    }  

    // Get a pointer to the codec context for the audio stream
    aCodecCtx = pFormatCtx-&gt;streams[audioStream]-&gt;codec;

    // Set audio settings from codec info
    SDL_AudioSpec wanted_spec;
    wanted_spec.freq = aCodecCtx-&gt;sample_rate;
    wanted_spec.format = AUDIO_S16SYS;
    wanted_spec.channels = aCodecCtx-&gt;channels;
    wanted_spec.silence = 0;
    wanted_spec.samples = SDL_AUDIO_BUFFER_SIZE;
    wanted_spec.callback = audio_callback;
    wanted_spec.userdata = aCodecCtx;

    SDL_AudioSpec spec;
    if (SDL_OpenAudio(&amp;wanted_spec, &amp;spec) &lt; 0) 
    {
        fprintf(stderr, "SDL_OpenAudio: %s\n", SDL_GetError());
        exit(-1);
    }

    AVCodec* aCodec = avcodec_find_decoder(aCodecCtx-&gt;codec_id);
    if (!aCodec) 
    {
        fprintf(stderr, "Unsupported codec!\n");
        exit(-1);
    }
    avcodec_open(aCodecCtx, aCodec);

    // audio_st = pFormatCtx-&gt;streams[index]
    packet_queue_init(&amp;audioq);
    SDL_PauseAudio(0); 

    // Get a pointer to the codec context for the video stream
    pCodecCtx = pFormatCtx-&gt;streams[videoStream]-&gt;codec;

    // Find the decoder for the video stream
    AVCodec* pCodec = avcodec_find_decoder(pCodecCtx-&gt;codec_id);
    if (pCodec == NULL) 
    {
        fprintf(stderr, "Unsupported codec!\n");
        exit(-1); // Codec not found
    }

    // Open codec
    if (avcodec_open(pCodecCtx, pCodec) &lt; 0)
    {
        fprintf(stderr, "Unsupported codec!\n");
        exit(-1); // Could not open codec
    }
}


int main(int argc, char* argv[])
{
    if (argc &lt; 2)
    {
        std::cout &lt;&lt; "Usage: " &lt;&lt; argv[0] &lt;&lt; " &lt;video&gt;" &lt;&lt; std::endl;
        return -1;
    }

    av_register_all();

    // Init SDL
    if (SDL_Init(SDL_INIT_VIDEO | SDL_INIT_AUDIO | SDL_INIT_TIMER)) 
    {
        fprintf(stderr, "Could not initialize SDL - %s\n", SDL_GetError());
        return -1;
    }

    // Init ffmpeg and setup some SDL stuff related to Audio
    setup_ffmpeg(argv[1]);

    VideoCapture cap(argv[1]); // open the default camera
    if (!cap.isOpened())  // check if we succeeded
    {
        std::cout &lt;&lt; "Failed to load file!" &lt;&lt; std::endl;
            return -1;
    }

    AVPacket packet;
    while (av_read_frame(pFormatCtx, &amp;packet) &gt;= 0) 
    {
        if (packet.stream_index == videoStream) 
        {
              // Actually this is were SYNC between audio/video would happen.
              // Right now I assume that every VIDEO packet contains an entire video frame, and that's not true. A video frame can be made by multiple packets!
              // But for the time being, assume 1 video frame == 1 video packet,
              // so instead of reading the frame through ffmpeg, I read it through OpenCV. 

              Mat frame;
              cap &gt;&gt; frame; // get a new frame from camera

          // do some processing on the frame, either as a Mat or as IplImage.
              // For educational purposes, applying a lame grayscale conversion
          IplImage ipl_frame = frame;
          for (int i = 0; i &lt; ipl_frame.width * ipl_frame.height * ipl_frame.nChannels; i += ipl_frame.nChannels)
          {
                ipl_frame.imageData[i] = (ipl_frame.imageData[i] + ipl_frame.imageData[i+1] + ipl_frame.imageData[i+2])/3;   //B
                ipl_frame.imageData[i+1] = (ipl_frame.imageData[i] + ipl_frame.imageData[i+1] + ipl_frame.imageData[i+2])/3; //G
                ipl_frame.imageData[i+2] = (ipl_frame.imageData[i] + ipl_frame.imageData[i+1] + ipl_frame.imageData[i+2])/3; //R
            }

            // Display it on SDL window
            show_frame(&amp;ipl_frame); 

            av_free_packet(&amp;packet);
        }   
        else if (packet.stream_index == audioStream) 
        {
            packet_queue_put(&amp;audioq, &amp;packet);
        } 
        else 
        {
            av_free_packet(&amp;packet);
        }

        SDL_Event event;
        SDL_PollEvent(&amp;event);
        switch (event.type) 
        {
            case SDL_QUIT:
                SDL_FreeSurface(surface);
                SDL_Quit();
                break;

            default:
                break;  
        }
    }

    // the camera will be deinitialized automatically in VideoCapture destructor

    // Close the codec
    avcodec_close(pCodecCtx);

    // Close the video file
    av_close_input_file(pFormatCtx);

    return 0;
}
</code></pre>

<p>On my Mac I compiled it with: </p>

<pre><code>g++ ffmpeg_snd.cpp -o ffmpeg_snd -D_GNU_SOURCE=1 -D_THREAD_SAFE -I/usr/local/include/opencv -I/usr/local/include -I/usr/local/include/SDL  -Wl,-framework,Cocoa -L/usr/local/lib -lopencv_core -lopencv_imgproc -lopencv_highgui -lopencv_ml -lopencv_video -lopencv_features2d -lopencv_calib3d -lopencv_objdetect -lopencv_contrib -lopencv_legacy -lopencv_flann -lSDLmain -lSDL -L/usr/local/lib -lavfilter -lavcodec -lavformat -I/usr/local/Cellar/ffmpeg/HEAD/include/libavcodec -I/usr/local/Cellar/ffmpeg/HEAD/include/libavformat
</code></pre>

                                    </div>
                                    <div class="d-flex justify-content-between align-items-center">
                                        <div class="profile-container">
                                            <div class="profile-details-container d-flex align-items-center">
                                                    <div class="asker-name" itemprop="author" itemscope itemtype="https://schema.org/Person">
                                                        <a href="https://stackoverflow.com/users/176769/karlphillip" target="_blank"><span itemprop="name">karlphillip</span></a>
                                                    </div>
                                            </div>
                                        </div>
                                    </div>
                                        <div style="display: none">
                                            <div itemprop="url">https://c.programmingpedia.net/en/knowledge-base/8187745/audio-output-with-video-processing-with-opencv#answer-0</div>
                                            <div itemprop="upvoteCount">46</div>
                                            <div itemprop="dateCreated">5/23/2017 12:02:06 PM</div>
                                        </div>
                                </div>
                            </div>
                            <br/>
                    </div>
                </div>
                <div class="text-center mt-5 mb-5">
                    <a href="https://stackoverflow.com/questions/8187745" class="btn-only d-inline-block stack-overflow-identity" target="_blank"><i class="fab fa-stack-overflow"></i> View more on Stack Overflow</a>
                </div>
            </div>
            
            <div class="attribution">
                <div>Licensed under: <a href="https://creativecommons.org/licenses/by-sa/3.0/" target="_blank">CC-BY-SA</a> with <a href="https://stackoverflow.blog/2009/06/25/attribution-required/" target="_blank">attribution</a></div>
                <div>Not affiliated with: <a href="https://stackoverflow.com/questions/tagged/dapper" target="_blank">Stack Overflow</a></div>
                
            </div>
        </div>

    </div>
</div>
            
        </div>
    </div>
    <div class="col-aside-right">
        <div class="col-aside-right-inner">
        </div>
    </div>
</div>
<div class="site-footer">
</div>
    
    <a href="#" id="scroll-to-top" class="back-to-top" style="display: inline;">Icon</a>

<!-- Optional JavaScript -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="http://code.jquery.com/jquery-3.4.1.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>

<script>
    $(function() {
        $('a').each(function() {
            var a = new RegExp('/' + window.location.host + '/');
            if (!a.test(this.href)) {
                $(this).attr("target", "_blank");
            }
        });

        $("table").addClass("table table-bordered table-hover table-responsive-sm table-striped");
        $("thead").addClass("thead-dark");

        $('aside a').each(function() {
            if ($(this).attr('href') == '/{{page.permalink}}' ||
                $(this).attr('href') == '{{ site.github.url }}/{{page.permalink}}') {
                $(this).addClass('font-weight-bold');
            }
        });
    });
</script>


</body>

<!-- Mirrored from c.programmingpedia.net/en/knowledge-base/8187745/audio-output-with-video-processing-with-opencv by HTTrack Website Copier/3.x [XR&CO'2014], Sat, 16 Jan 2021 10:13:58 GMT -->
</html>
